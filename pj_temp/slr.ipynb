{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3339c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import  LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f139933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialised ImageDataGenerator from tensorflow module to preprocess the image\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=15,     \n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        featurewise_center=True,\n",
    "        width_shift_range=0.05,   \n",
    "        height_shift_range=0.05,\n",
    "        zoom_range=0.1,\n",
    "        fill_mode='nearest') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b32b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to all images files of dataset - each folder - alphabet contains 100 images\n",
    "Patha=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/a/*.jpg\"\n",
    "Pathb=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/b/*.jpg\"\n",
    "Pathc=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/c/*.jpg\"\n",
    "Pathd=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/d/*.jpg\"\n",
    "Pathe=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/e/*.jpg\"\n",
    "Pathf=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/f/*.jpg\"\n",
    "Pathg=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/g/*.jpg\"\n",
    "Pathh=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/h/*.jpg\"\n",
    "Pathi=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/i/*.jpg\"\n",
    "Pathj=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/j/*.jpg\"\n",
    "Pathk=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/k/*.jpg\"\n",
    "Pathl=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/l/*.jpg\"\n",
    "Pathm=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/m/*.jpg\"\n",
    "Pathn=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/n/*.jpg\"\n",
    "Patho=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/o/*.jpg\"\n",
    "Pathp=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/p/*.jpg\"\n",
    "Pathq=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/q/*.jpg\"\n",
    "Pathr=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/r/*.jpg\"\n",
    "Paths=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/s/*.jpg\"\n",
    "Patht=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/t/*.jpg\"\n",
    "Pathu=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/u/*.jpg\"\n",
    "Pathv=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/v/*.jpg\"\n",
    "Pathw=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/w/*.jpg\"\n",
    "Pathx=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/x/*.jpg\"\n",
    "Pathy=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/y/*.jpg\"\n",
    "Pathz=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/dataset/z/*.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f1bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data from each alphabet folder and club into final dataframe\n",
    "def importing_data(path):\n",
    "    sample = []\n",
    "    for filename in glob.glob(path):\n",
    "        img = Image.open(filename,'r')\n",
    "        img = img.resize((128,128))\n",
    "        sample.append(img)\n",
    "        \n",
    "    return sample\n",
    "\n",
    "data_a = importing_data(Patha)\n",
    "data_b = importing_data(Pathb)\n",
    "data_c = importing_data(Pathc)\n",
    "data_d = importing_data(Pathd)\n",
    "data_e = importing_data(Pathe)\n",
    "data_f = importing_data(Pathf)\n",
    "data_g = importing_data(Pathg)\n",
    "data_h = importing_data(Pathh)\n",
    "data_i = importing_data(Pathi)\n",
    "data_j = importing_data(Pathj)\n",
    "data_k = importing_data(Pathk)\n",
    "data_l = importing_data(Pathl)\n",
    "data_m = importing_data(Pathm)\n",
    "data_n = importing_data(Pathn)\n",
    "data_o = importing_data(Patho)\n",
    "data_p = importing_data(Pathp)\n",
    "data_q = importing_data(Pathq)\n",
    "data_r = importing_data(Pathr)\n",
    "data_s = importing_data(Paths)\n",
    "data_t = importing_data(Patht)\n",
    "data_u = importing_data(Pathu)\n",
    "data_v = importing_data(Pathv)\n",
    "data_w = importing_data(Pathw)\n",
    "data_x = importing_data(Pathx)\n",
    "data_y = importing_data(Pathy)\n",
    "data_z = importing_data(Pathz)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a623bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z):\n",
    "    df_data_a = pd.DataFrame({'image':a, 'label': 'a'})\n",
    "    df_data_b = pd.DataFrame({'image':b, 'label': 'b'})\n",
    "    df_data_c = pd.DataFrame({'image':c, 'label': 'c'})\n",
    "    df_data_d = pd.DataFrame({'image':d, 'label': 'd'})\n",
    "    df_data_e = pd.DataFrame({'image':e, 'label': 'e'})\n",
    "    df_data_f = pd.DataFrame({'image':f, 'label': 'f'})\n",
    "    df_data_g = pd.DataFrame({'image':g, 'label': 'g'})\n",
    "    df_data_h = pd.DataFrame({'image':h, 'label': 'h'})\n",
    "    df_data_i = pd.DataFrame({'image':i, 'label': 'i'})\n",
    "    df_data_j = pd.DataFrame({'image':j, 'label': 'j'})\n",
    "    df_data_k = pd.DataFrame({'image':k, 'label': 'k'})\n",
    "    df_data_l = pd.DataFrame({'image':l, 'label': 'l'})\n",
    "    df_data_m = pd.DataFrame({'image':m, 'label': 'm'})\n",
    "    df_data_n = pd.DataFrame({'image':n, 'label': 'n'})\n",
    "    df_data_o = pd.DataFrame({'image':o, 'label': 'o'})\n",
    "    df_data_p = pd.DataFrame({'image':p, 'label': 'p'})\n",
    "    df_data_q = pd.DataFrame({'image':q, 'label': 'q'})\n",
    "    df_data_r = pd.DataFrame({'image':r, 'label': 'r'})\n",
    "    df_data_s = pd.DataFrame({'image':s, 'label': 's'})\n",
    "    df_data_t = pd.DataFrame({'image':t, 'label': 't'})\n",
    "    df_data_u = pd.DataFrame({'image':u, 'label': 'u'})\n",
    "    df_data_v = pd.DataFrame({'image':v, 'label': 'v'})\n",
    "    df_data_w = pd.DataFrame({'image':w, 'label': 'w'})\n",
    "    df_data_x = pd.DataFrame({'image':x, 'label': 'x'})\n",
    "    df_data_y = pd.DataFrame({'image':y, 'label': 'y'})\n",
    "    df_data_z = pd.DataFrame({'image':z, 'label': 'z'})\n",
    "    \n",
    "  \n",
    "    \n",
    "    final_data = [df_data_a, df_data_b, df_data_c, df_data_d, df_data_e, df_data_f, df_data_g, df_data_h, df_data_i, df_data_j, df_data_k, df_data_l, df_data_m, df_data_n, df_data_o, df_data_p, df_data_q, df_data_r, df_data_s, df_data_t, df_data_u, df_data_v, df_data_w, df_data_x, df_data_y, df_data_z]\n",
    "    final_data = pd.concat(final_data)\n",
    "    all_data = final_data['image']\n",
    "    labels = final_data['label']\n",
    "    all_data=np.stack(all_data,axis=0)\n",
    "    labels = LabelBinarizer().fit_transform(labels)\n",
    "    return all_data,labels\n",
    "\n",
    "dataset,labels   = data_import(data_a,data_b,data_c,data_d,data_e,data_f,data_g,data_h,data_i,data_j,data_k,data_l,data_m,data_n,data_o,data_p,data_q,data_r,data_s,data_t,data_u,data_v,data_w,data_x,data_y,data_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c7cdd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600, 128, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5cb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.reshape(2600,128,128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19790612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation method while preprocessing images\n",
    "def augmentation(dataset,labels,counts):\n",
    "    augs=[]\n",
    "    augs_data=[]\n",
    "    augs_labels=[]\n",
    "    i=0\n",
    "    for batch in datagen.flow(dataset,labels,\n",
    "                          batch_size=260):\n",
    "        i += 1\n",
    "        augs.append(batch)\n",
    "        if i>counts:\n",
    "            break\n",
    "    augs_data=[]\n",
    "    for i in range(counts):\n",
    "        data=augs[i][0]\n",
    "        augs_data.append(data) \n",
    "    x = np.vstack(augs_data)\n",
    "    x = x/255.0\n",
    "    \n",
    "    for i in range(counts):\n",
    "        label=augs[i][1]\n",
    "        augs_labels.append(label) \n",
    "    y = np.vstack(augs_labels)        \n",
    "    return x, y\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deaf4286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#augment all the images in dataset\n",
    "x,y = augmentation(dataset,labels,15)\n",
    "y = np.where(y==1)[1]\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_onehot = to_categorical(y)\n",
    " \n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y_onehot,test_size=0.26,random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1cc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_input (InputLayer)   [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 12)      312       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 12)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 24)        7224      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 24)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 36)        21636     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 36)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 36)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 48)        43248     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 48)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 6, 48)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1728)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               207480    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               12100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 60)                6060      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 26)                1586      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 303,306\n",
      "Trainable params: 303,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "37/37 [==============================] - 18s 446ms/step - loss: 4.1377 - accuracy: 0.0342 - val_loss: 3.8877 - val_accuracy: 0.0363\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 18s 491ms/step - loss: 3.6440 - accuracy: 0.0364 - val_loss: 3.3415 - val_accuracy: 0.0398\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 19s 498ms/step - loss: 3.1745 - accuracy: 0.0394 - val_loss: 2.8767 - val_accuracy: 0.0398\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 17s 461ms/step - loss: 2.7742 - accuracy: 0.0347 - val_loss: 2.5300 - val_accuracy: 0.0363\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 18s 475ms/step - loss: 2.4476 - accuracy: 0.0399 - val_loss: 2.2349 - val_accuracy: 0.0363\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 17s 463ms/step - loss: 2.1613 - accuracy: 0.0399 - val_loss: 1.9744 - val_accuracy: 0.0363\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 17s 467ms/step - loss: 1.9081 - accuracy: 0.0373 - val_loss: 1.7405 - val_accuracy: 0.0363\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 17s 468ms/step - loss: 1.6753 - accuracy: 0.0381 - val_loss: 1.5240 - val_accuracy: 0.0363\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 19s 510ms/step - loss: 1.4692 - accuracy: 0.0342 - val_loss: 1.3309 - val_accuracy: 0.0363\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 19s 512ms/step - loss: 1.2832 - accuracy: 0.0399 - val_loss: 1.1546 - val_accuracy: 0.0363\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 17s 470ms/step - loss: 1.1113 - accuracy: 0.0342 - val_loss: 0.9948 - val_accuracy: 0.0363\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 19s 509ms/step - loss: 0.9564 - accuracy: 0.0347 - val_loss: 0.8506 - val_accuracy: 0.0381\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 18s 479ms/step - loss: 0.8171 - accuracy: 0.0407 - val_loss: 0.7224 - val_accuracy: 0.0398\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 17s 450ms/step - loss: 0.6925 - accuracy: 0.0381 - val_loss: 0.6102 - val_accuracy: 0.0398\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - 17s 470ms/step - loss: 0.5851 - accuracy: 0.0347 - val_loss: 0.5070 - val_accuracy: 0.0398\n",
      "Epoch 16/50\n",
      "37/37 [==============================] - 19s 509ms/step - loss: 0.4887 - accuracy: 0.0433 - val_loss: 0.4209 - val_accuracy: 0.0398\n",
      "Epoch 17/50\n",
      "37/37 [==============================] - 18s 496ms/step - loss: 0.4102 - accuracy: 0.0351 - val_loss: 0.3482 - val_accuracy: 0.0398\n",
      "Epoch 18/50\n",
      "37/37 [==============================] - 19s 508ms/step - loss: 0.3402 - accuracy: 0.0433 - val_loss: 0.2881 - val_accuracy: 0.0398\n",
      "Epoch 19/50\n",
      "37/37 [==============================] - 18s 500ms/step - loss: 0.2855 - accuracy: 0.0373 - val_loss: 0.2408 - val_accuracy: 0.0398\n",
      "Epoch 20/50\n",
      "37/37 [==============================] - 17s 453ms/step - loss: 0.2437 - accuracy: 0.0407 - val_loss: 0.2058 - val_accuracy: 0.0398\n",
      "Epoch 21/50\n",
      "37/37 [==============================] - 17s 466ms/step - loss: 0.2133 - accuracy: 0.0412 - val_loss: 0.1831 - val_accuracy: 0.0398\n",
      "Epoch 22/50\n",
      "37/37 [==============================] - 18s 499ms/step - loss: 0.1974 - accuracy: 0.0377 - val_loss: 0.1732 - val_accuracy: 0.0398\n",
      "Epoch 23/50\n",
      "37/37 [==============================] - 17s 457ms/step - loss: 0.1910 - accuracy: 0.0373 - val_loss: 0.1704 - val_accuracy: 0.0346\n",
      "Epoch 24/50\n",
      "37/37 [==============================] - 19s 509ms/step - loss: 0.1884 - accuracy: 0.0373 - val_loss: 0.1687 - val_accuracy: 0.0346\n",
      "Epoch 25/50\n",
      "37/37 [==============================] - 18s 482ms/step - loss: 0.1865 - accuracy: 0.0368 - val_loss: 0.1679 - val_accuracy: 0.0346\n",
      "Epoch 26/50\n",
      "37/37 [==============================] - 17s 462ms/step - loss: 0.1838 - accuracy: 0.0472 - val_loss: 0.1672 - val_accuracy: 0.0346\n",
      "Epoch 27/50\n",
      "37/37 [==============================] - 17s 461ms/step - loss: 0.1835 - accuracy: 0.0325 - val_loss: 0.1666 - val_accuracy: 0.0398\n",
      "Epoch 28/50\n",
      "37/37 [==============================] - 17s 460ms/step - loss: 0.1829 - accuracy: 0.0360 - val_loss: 0.1662 - val_accuracy: 0.0398\n",
      "Epoch 29/50\n",
      "37/37 [==============================] - 17s 465ms/step - loss: 0.1835 - accuracy: 0.0399 - val_loss: 0.1658 - val_accuracy: 0.0398\n",
      "Epoch 30/50\n",
      "37/37 [==============================] - 17s 462ms/step - loss: 0.1810 - accuracy: 0.0407 - val_loss: 0.1656 - val_accuracy: 0.0398\n",
      "Epoch 31/50\n",
      "37/37 [==============================] - 17s 462ms/step - loss: 0.1814 - accuracy: 0.0429 - val_loss: 0.1653 - val_accuracy: 0.0398\n",
      "Epoch 32/50\n",
      "37/37 [==============================] - 17s 470ms/step - loss: 0.1810 - accuracy: 0.0351 - val_loss: 0.1657 - val_accuracy: 0.0398\n",
      "Epoch 33/50\n",
      "37/37 [==============================] - 18s 488ms/step - loss: 0.1790 - accuracy: 0.0468 - val_loss: 0.1656 - val_accuracy: 0.0346\n",
      "Epoch 34/50\n",
      "23/37 [=================>............] - ETA: 6s - loss: 0.1802 - accuracy: 0.0374"
     ]
    }
   ],
   "source": [
    "#preprocess and train the data with cnn model layering\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, MaxPooling2D, Conv2D, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(12, (5, 5), activation='relu', padding='same', input_shape=(128, 128, 1)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(24, (5, 5), activation='relu', padding='same',\n",
    "                 kernel_regularizer =tf.keras.regularizers.l1(l=0.01)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(36, (5, 5), activation='relu', padding='same',\n",
    "                 kernel_regularizer =tf.keras.regularizers.l2(l=0.01)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), activation='relu',\n",
    "                 kernel_regularizer =tf.keras.regularizers.l2(l=0.01)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "\n",
    "m = model.output\n",
    "m = Dense(120, activation = \"relu\")(m)\n",
    "m = Dense(100, activation = \"relu\")(m)\n",
    "m = Dropout(0.2)(m)\n",
    "m = Dense(60, activation = \"relu\")(m)\n",
    "m = Dense(60, activation = \"relu\")(m)\n",
    "m = Dropout(0.2)(m)\n",
    "final_layer =  Dense(26, activation = \"softmax\")(m)\n",
    "\n",
    " \n",
    "cnn_model = Model(inputs=model.input, outputs=final_layer)\n",
    "\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "cnn_model.compile(optimizer=Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "callback = EarlyStopping(monitor='val_loss',patience=5, \n",
    "                         restore_best_weights=True)\n",
    "\n",
    "history=cnn_model.fit(x_train, y_train, validation_split=0.2, \n",
    "                  epochs=50 , batch_size=64,callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb75ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataset and fit into algo and  confusion matrix, classification report\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = cnn_model.predict(x_test)    \n",
    "pred_labels = np.argmax(predictions, axis = 1)\n",
    "tests=np.argmax(y_test,axis=1)\n",
    "\n",
    "conf_mx = confusion_matrix(tests, pred_labels)\n",
    "conf_mx\n",
    "\n",
    "heat_cm = pd.DataFrame(conf_mx, columns=(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\n",
    "                                  \"w\",\"x\",\"y\",\"z\"), index =(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\"\n",
    "                                                                       ,\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"))\n",
    "heat_cm.index.name = 'Actual'\n",
    "heat_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4) \n",
    "sn.heatmap(heat_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(classification_report(tests, pred_labels))\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "plt.plot(history_df.loc[:, ['accuracy']], label='accuracy')\n",
    "plt.plot(history_df.loc[:, ['val_accuracy']], label='val_accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_df.loc[:, ['loss']], label='loss')\n",
    "plt.plot(history_df.loc[:, ['val_loss']], label='val_loss')\n",
    "\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948af0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the test data is loaded in test folder, were imported and clubbed into final df\n",
    "externala=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/a/*.jpg\"\n",
    "externalb=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/b/*.jpg\"\n",
    "externalc=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/c/*.jpg\"\n",
    "externald=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/d/*.jpg\"\n",
    "externale=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/e/*.jpg\"\n",
    "externalf=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/f/*.jpg\"\n",
    "externalg=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/g/*.jpg\"\n",
    "externalh=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/h/*.jpg\"\n",
    "externali=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/i/*.jpg\"\n",
    "externalj=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/j/*.jpg\"\n",
    "externalk=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/k/*.jpg\"\n",
    "externall=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/l/*.jpg\"\n",
    "externalm=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/m/*.jpg\"\n",
    "externaln=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/n/*.jpg\"\n",
    "externalo=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/o/*.jpg\"\n",
    "externalp=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/p/*.jpg\"\n",
    "externalq=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/q/*.jpg\"\n",
    "externalr=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/r/*.jpg\"\n",
    "externals=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/s/*.jpg\"\n",
    "externalt=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/t/*.jpg\"\n",
    "externalu=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/u/*.jpg\"\n",
    "externalv=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/v/*.jpg\"\n",
    "externalw=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/w/*.jpg\"\n",
    "externalx=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/x/*.jpg\"\n",
    "externaly=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/y/*.jpg\"\n",
    "externalz=\"C:/Users/thipp/Fall2022/CS5710_13469/Sign Language for Alphabets/test/z/*.jpg\"\n",
    "\n",
    "external_test_a = importing_data(externala)\n",
    "external_test_b = importing_data(externalb)\n",
    "external_test_c = importing_data(externalc)\n",
    "external_test_d= importing_data(externald)\n",
    "external_test_e= importing_data(externale)\n",
    "external_test_f= importing_data(externalf)\n",
    "external_test_g= importing_data(externalg)\n",
    "external_test_h= importing_data(externalh)\n",
    "external_test_i= importing_data(externali)\n",
    "external_test_j= importing_data(externalj)\n",
    "external_test_k= importing_data(externalk)\n",
    "external_test_l= importing_data(externall)\n",
    "external_test_m= importing_data(externalm)\n",
    "external_test_n= importing_data(externaln)\n",
    "external_test_o= importing_data(externalo)\n",
    "external_test_p= importing_data(externalp)\n",
    "external_test_q= importing_data(externalq)\n",
    "external_test_r= importing_data(externalr)\n",
    "external_test_s= importing_data(externals)\n",
    "external_test_t= importing_data(externalt)\n",
    "external_test_u= importing_data(externalu)\n",
    "external_test_v= importing_data(externalv)\n",
    "external_test_w= importing_data(externalw)\n",
    "external_test_x= importing_data(externalx)\n",
    "external_test_y= importing_data(externaly)\n",
    "external_test_z= importing_data(externalz)\n",
    "\n",
    "\n",
    "external_test_data,external_test_label   = data_import(external_test_a,external_test_b,external_test_c,external_test_d,\n",
    "                                                       external_test_e,external_test_f,external_test_g,external_test_h,\n",
    "                                                       external_test_i,external_test_j,external_test_k,external_test_l,\n",
    "                                                       external_test_m,external_test_n,external_test_o,external_test_p,\n",
    "                                                       external_test_q,external_test_r,external_test_s,external_test_t,\n",
    "                                                       external_test_u,external_test_v,external_test_w,external_test_x,\n",
    "                                                      external_test_y,external_test_z)\n",
    "\n",
    "print(external_test_data.shape)\n",
    "external_test_data=external_test_data.reshape(501,128,128,1)\n",
    "external_test_data = external_test_data /255.0\n",
    "\n",
    "external_test_pred = cnn_model.predict(external_test_data)   \n",
    "external_pred_labels = np.argmax(external_test_pred, axis = 1) \n",
    "external_tests=np.argmax(external_test_label,axis=1)\n",
    "\n",
    "\n",
    "external_conf_mx = confusion_matrix(external_tests, external_pred_labels)\n",
    "heat_cm = pd.DataFrame(external_conf_mx,\n",
    "                       columns=(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\") \n",
    "                       ,index =(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"))\n",
    "heat_cm.index.name = 'Actual'\n",
    "heat_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4) \n",
    "sn.heatmap(heat_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63722a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_for_ml = model.predict(x_train)\n",
    "x_test_ml = model.predict(x_test)\n",
    "y_train_ml = np.where(y_train==1)[1]\n",
    "y_test_ml = np.where(y_test==1)[1]\n",
    "external_data_ml = model.predict(external_test_data)\n",
    "external_label_ml = np.where(external_test_label==1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5130f1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#common method to execute various machine learning algorithms and their performances\n",
    "def machine_learning(algorithm):\n",
    "    algorithm.fit(x_for_ml, y_train_ml)\n",
    "    \n",
    "    prediction_algo = algorithm.predict(x_test_ml)\n",
    "    cm_algo = confusion_matrix(y_test_ml, prediction_algo)\n",
    "    heat_cm = pd.DataFrame(cm_algo, columns=(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\n",
    "                                             \"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"),\n",
    "                                             index=(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\"\n",
    "                                                    ,\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"))\n",
    "    heat_cm.index.name = 'Actual'\n",
    "    heat_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.set(font_scale=1.4) \n",
    "    sn.heatmap(heat_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g')\n",
    "    cm_algo=plt.show()\n",
    "    \n",
    "    report = print(classification_report(y_test_ml, prediction_algo))\n",
    "    algo_accuracy =  accuracy_score(y_test_ml, prediction_algo)\n",
    "    \n",
    "    prediction_self_algo = algorithm.predict(external_data_ml)\n",
    "    cm_self_algo = confusion_matrix(external_label_ml, prediction_self_algo)\n",
    "    algo_test_accuracy = accuracy_score(external_label_ml, prediction_self_algo)\n",
    "    heat_cm = pd.DataFrame(cm_self_algo, columns=(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"), \n",
    "                           index =(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"))\n",
    "    heat_cm.index.name = 'Actual'\n",
    "    heat_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.set(font_scale=1.4) \n",
    "    sn.heatmap(heat_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g')\n",
    "    cm_self_algo=plt.show()\n",
    "    return cm_algo, report, cm_self_algo, algo_accuracy, algo_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1301e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def machine_learning1(algorithm):\n",
    "    #fit the training data into ML algorithm\n",
    "    algorithm.fit(x_for_ml, y_train_ml)\n",
    "    #Predict the data using test\n",
    "    prediction_algo = algorithm.predict(x_test_ml)\n",
    "    #confustion matrix\n",
    "    cm_algo = confusion_matrix(y_test_ml, prediction_algo)\n",
    "    #plotting the confusion matrix\n",
    "    heat_cm = pd.DataFrame(cm_algo, columns=(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\n",
    "                                             \"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"),\n",
    "                                             index=(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\"\n",
    "                                                    ,\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"))\n",
    "    heat_cm.index.name = 'Actual'\n",
    "    heat_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.set(font_scale=1.4) \n",
    "    sn.heatmap(heat_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g')\n",
    "    cm_algo=plt.show()\n",
    "    #classification report of training data\n",
    "    report = print(classification_report(y_test_ml, prediction_algo))\n",
    "    #accuracy of training data\n",
    "    algo_accuracy =  accuracy_score(y_test_ml, prediction_algo)\n",
    "    \n",
    "    \n",
    "    #predicting the external test dataset\n",
    "    prediction_self_algo = algorithm.predict(external_data_ml)\n",
    "    #test dataset confusion matrix\n",
    "    cm_self_algo = confusion_matrix(external_label_ml, prediction_self_algo)\n",
    "    #test dataset accuracy\n",
    "    algo_test_accuracy = accuracy_score(external_label_ml, prediction_self_algo)\n",
    "    heat_cm = pd.DataFrame(cm_self_algo, columns=(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"), \n",
    "                           index =(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"))\n",
    "    heat_cm.index.name = 'Actual'\n",
    "    heat_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.set(font_scale=1.4) \n",
    "    sn.heatmap(heat_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g')\n",
    "    cm_self_algo=plt.show()\n",
    "    return cm_algo, report, cm_self_algo, algo_accuracy, algo_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79cce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XgBoost Algorithm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgboost = XGBClassifier(n_estimators=50,learning_rate=0.1, \n",
    "                        max_depth=2,reg_lambda=0.1)\n",
    "\n",
    "xgb_cm, xgb_report, xgb_external_cm, xgb_acc, xgb_ext_acc = machine_learning(xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% LGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(n_estimators=500,random_state=2021)\n",
    "\n",
    "lgbm_cm, lgbm_report,lgbm_cm_external,lgb_acc, lgb_ext_acc = machine_learning(lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cccaafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support vector machine\n",
    "from sklearn.svm import SVC\n",
    "SVCClf = SVC(kernel = 'linear',gamma = 'scale', shrinking = False,)\n",
    "\n",
    "SVCClf_cm, SVCClf_report,SVCClf_cm_external, svc_acc, svc_ext_acc = machine_learning1(SVCClf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\", random_state=42,max_depth=3, min_samples_leaf=5)\n",
    "clf_cm, clf_report,clf_cm_external, clf_acc, clf_ext_acc = machine_learning1(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac6ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "\n",
    "logreg = LogisticRegression(random_state = 0)  \n",
    "logreg_cm, logreg_report,logreg_cm_external, logreg_acc, logreg_ext_acc = machine_learning1(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100)\n",
    "rf_clf_cm, rf_clf_report,rf_clf_cm_external, rf_acc, rf_ext_acc = machine_learning1(rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d277590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuary of each alogirthm displaying as table\n",
    "res_table = pd.DataFrame({\n",
    "    'Model': ['XGBoost','LGBM','SVC','Decision Tree','Logistic Regression','Random Forest'],\n",
    "    'Train Score': [xgb_acc,lgb_acc,svc_acc,clf_acc,logreg_acc,rf_acc],\n",
    "    'Test Score' : [xgb_ext_acc,lgb_ext_acc,svc_ext_acc,clf_ext_acc,logreg_ext_acc,rf_ext_acc]})\n",
    "res_table.sort_values(by='Train Score', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
